# Copyright 2019-2022 The Tekton Authors
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: hook
  labels:
    app: hook
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  selector:
    matchLabels:
      app: hook
  template:
    metadata:
      labels:
        app: hook
    spec:
      serviceAccountName: "hook"
      terminationGracePeriodSeconds: 180
      containers:
      - name: hook
        image: ghcr.io/tektoncd/plumbing/k8s-prow/hook:v20220628-aa928caf31
        imagePullPolicy: Always
        args:
        - --dry-run=false
        - --config-path=/etc/config/config.yaml
        - --github-endpoint=http://ghproxy
        - --github-endpoint=https://api.github.com
        - --github-token-path=/etc/github/oauth
        ports:
          - name: http
            containerPort: 8888
          - name: metrics
            containerPort: 9090
        volumeMounts:
        - name: hmac
          mountPath: /etc/webhook
          readOnly: true
        - name: oauth
          mountPath: /etc/github
          readOnly: true
        - name: config
          mountPath: /etc/config
          readOnly: true
        - name: plugins
          mountPath: /etc/plugins
          readOnly: true
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 3
          periodSeconds: 3
        readinessProbe:
          httpGet:
            path: /healthz/ready
            port: 8081
          initialDelaySeconds: 10
          periodSeconds: 3
          timeoutSeconds: 600
      volumes:
      - name: hmac
        secret:
          secretName: hmac-token
      - name: oauth
        secret:
          secretName: oauth-token
      - name: config
        configMap:
          name: config
      - name: plugins
        configMap:
          name: plugins
---
apiVersion: v1
kind: Service
metadata:
  name: hook
  namespace: default
spec:
  externalTrafficPolicy: Cluster
  ports:
  - name: main
    port: 8888
    protocol: TCP
    targetPort: 8888
  - name: metrics
    port: 9090
    protocol: TCP
  selector:
    app: hook
  sessionAffinity: None
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: prow-controller-manager
  labels:
    app: prow-controller-manager
spec:
  # Mutually exclusive with plank. Only one of them may have more than zero replicas.
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  revisionHistoryLimit: 2
  selector:
    matchLabels:
      app: prow-controller-manager
  template:
    metadata:
      labels:
        app: prow-controller-manager
    spec:
      serviceAccountName: prow-controller-manager
      containers:
      - name: prow-controller-manager
        image: ghcr.io/tektoncd/plumbing/k8s-prow/prow-controller-manager:v20220628-aa928caf31
        args:
        - --config-path=/etc/config/config.yaml
        - --dry-run=false
        - --enable-controller=plank
        ports:
        - name: metrics
          containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
        - name: oauth
          mountPath: /etc/github
          readOnly: true
        livenessProbe: # Pod is killed if this fails 3 times.
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 10
          periodSeconds: 5
        readinessProbe: # Pod is not considered ready (for rolling deploy and request routing) if this fails 3 times.
          httpGet:
            path: /healthz/ready
            port: 8081
          initialDelaySeconds: 10
          periodSeconds: 3
      volumes:
      - name: config
        configMap:
          name: config
      - name: oauth
        secret:
          secretName: oauth-token
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prow-controller-manager
  namespace: default
  name: prow-controller-manager
spec:
  ports:
    - name: metrics
      port: 9090
      protocol: TCP
  selector:
    app: prow-controller-manager
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: sinker
  labels:
    app: sinker
spec:
  selector:
    matchLabels:
      app: sinker
  replicas: 1
  template:
    metadata:
      labels:
        app: sinker
    spec:
      serviceAccountName: "sinker"
      containers:
      - name: sinker
        image: ghcr.io/tektoncd/plumbing/k8s-prow/sinker:v20220628-aa928caf31
        ports:
        - name: metrics
          containerPort: 9090
        args:
        - --config-path=/etc/config/config.yaml
        - --dry-run=false
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: config
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: sinker
  namespace: default
  name: sinker
spec:
  ports:
    - name: metrics
      port: 9090
  selector:
    app: sinker
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: deck
  labels:
    app: deck
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  selector:
    matchLabels:
      app: deck
  template:
    metadata:
      labels:
        app: deck
    spec:
      serviceAccountName: "deck"
      terminationGracePeriodSeconds: 30
      containers:
      - name: deck
        image: ghcr.io/tektoncd/plumbing/k8s-prow/deck:v20220628-aa928caf31
        args:
        - --config-path=/etc/config/config.yaml
        - --tide-url=http://tide:8888/
        - --hook-url=http://hook:8888/plugin-help
        - --redirect-http-to=prow.tekton.dev
        - --oauth-url=/github-login
        - --spyglass=true
        - --rerun-creates-job
        - --github-token-path=/etc/github/oauth
        - --github-endpoint=http://ghproxy
        - --github-endpoint=https://api.github.com
        - --github-oauth-config-file=/etc/githuboauth/secret
        - --cookie-secret=/etc/cookie/secret
        - --plugin-config=/etc/plugins/plugins.yaml
        ports:
        - name: http
          containerPort: 8080
        - name: metrics
          containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
        - name: oauth-config
          mountPath: /etc/githuboauth
          readOnly: true
        - name: oauth-token
          mountPath: /etc/github
          readOnly: true
        - name: cookie-secret
          mountPath: /etc/cookie
          readOnly: true
        - name: plugins
          mountPath: /etc/plugins
          readOnly: true
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 3
          periodSeconds: 3
        readinessProbe:
          httpGet:
            path: /healthz/ready
            port: 8081
          initialDelaySeconds: 10
          periodSeconds: 3
          timeoutSeconds: 600
      volumes:
      - name: config
        configMap:
          name: config
      - name: oauth-config
        secret:
          secretName: github-oauth-config
      - name: oauth-token
        secret:
          secretName: oauth-token
      - name: cookie-secret
        secret:
          secretName: cookie
      - name: plugins
        configMap:
          name: plugins
---
apiVersion: v1
kind: Service
metadata:
  name: deck
  namespace: default
spec:
  externalTrafficPolicy: Cluster
  ports:
  - name: main
    port: 80
    protocol: TCP
    targetPort: 8080
  - name: metrics
    port: 9090
    protocol: TCP
  selector:
    app: deck
  sessionAffinity: None
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: horologium
  labels:
    app: horologium
spec:
  replicas: 1 # Do not scale up.
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: horologium
  template:
    metadata:
      labels:
        app: horologium
    spec:
      serviceAccountName: "horologium"
      terminationGracePeriodSeconds: 30
      containers:
      - name: horologium
        image: ghcr.io/tektoncd/plumbing/k8s-prow/horologium:v20220628-aa928caf31
        args:
        - --config-path=/etc/config/config.yaml
        - --dry-run=false
        ports:
        - name: metrics
          containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: config
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: horologium
  namespace: default
  name: horologium
spec:
  ports:
    - name: metrics
      port: 9090
      protocol: TCP
  selector:
    app: horologium
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: tide
  labels:
    app: tide
spec:
  replicas: 1 # Do not scale up.
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: tide
  template:
    metadata:
      labels:
        app: tide
    spec:
      serviceAccountName: "tide"
      containers:
      - name: tide
        image: ghcr.io/tektoncd/plumbing/k8s-prow/tide:v20220628-aa928caf31
        args:
        - --dry-run=false
        - --config-path=/etc/config/config.yaml
        - --github-endpoint=http://ghproxy
        - --github-endpoint=https://api.github.com
        - --github-token-path=/etc/github/oauth
        - --config-path=/etc/config/config.yaml
        # - --history-uri=gs://tekton-prow/tide-history.json
        # - --status-path=gs://tekton-prow/tide-status-checkpoint.yaml
        ports:
          - name: http
            containerPort: 8888
          - name: metrics
            containerPort: 9090
        volumeMounts:
        - name: oauth
          mountPath: /etc/github
          readOnly: true
        - name: config
          mountPath: /etc/config
          readOnly: true
      volumes:
      - name: oauth
        secret:
          secretName: oauth-token
      - name: config
        configMap:
          name: config
---
apiVersion: v1
kind: Service
metadata:
  name: tide
  namespace: default
spec:
  externalTrafficPolicy: Cluster
  ports:
  - name: main
    port: 8888
    protocol: TCP
  - name: metrics
    port: 9090
    protocol: TCP
  selector:
    app: tide
  sessionAffinity: None
  type: NodePort
#---
#
# TODO(#54) This component was added after our initial Prow setup
#
#apiVersion: apps/v1
#kind: Deployment
#metadata:
#  name: statusreconciler
#  namespace: default
#  labels:
#    app: statusreconciler
#spec:
#  replicas: 1
#  selector:
#    matchLabels:
#      app: statusreconciler
#  template:
#    metadata:
#      labels:
#        app: statusreconciler
#    spec:
#      serviceAccountName: statusreconciler
#      terminationGracePeriodSeconds: 180
#      containers:
#      - name: statusreconciler
#        image: ghcr.io/tektoncd/plumbing/k8s-prow/status-reconciler:v20190731-e3f7b9853
#        args:
#        - --dry-run=false
#        - --continue-on-error=true
#        - --plugin-config=/etc/plugins/plugins.yaml
#        - --config-path=/etc/config/config.yaml
#        - --github-token-path=/etc/github/oauth
#        volumeMounts:
#        - name: oauth
#          mountPath: /etc/github
#          readOnly: true
#        - name: config
#          mountPath: /etc/config
#          readOnly: true
#        - name: plugins
#          mountPath: /etc/plugins
#          readOnly: true
#      volumes:
#      - name: oauth
#        secret:
#          secretName: oauth-token
#      - name: config
#        configMap:
#          name: config
#      - name: plugins
#        configMap:
#          name: plugins
---
apiVersion: v1
kind: Namespace
metadata:
  name: test-pods
---
kind: ServiceAccount
apiVersion: v1
metadata:
  namespace: default
  name: "deck"
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "deck"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "deck"
subjects:
- kind: ServiceAccount
  name: "deck"
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: test-pods
  name: "deck"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "deck"
subjects:
- kind: ServiceAccount
  name: "deck"
  namespace: default
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: deck
rules:
  - apiGroups:
      - "prow.k8s.io"
    resources:
      - prowjobs
    verbs:
      - get
      - list
      - watch
      # Required when deck runs with `--rerun-creates-job=true`
      # **Warning:** Only use this for non-public deck instances, this allows
      # anyone with access to your Deck instance to create new Prowjobs
      # - create
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: test-pods
  name: deck
rules:
  - apiGroups:
      - ""
    resources:
      - pods/log
    verbs:
      - get
---
kind: ServiceAccount
apiVersion: v1
metadata:
  namespace: default
  name: "horologium"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "horologium"
rules:
  - apiGroups:
      - "prow.k8s.io"
    resources:
      - prowjobs
    verbs:
      - create
      - list
      - watch
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "horologium"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "horologium"
subjects:
- kind: ServiceAccount
  name: "horologium"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: default
  name: "prow-controller-manager"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "prow-controller-manager"
rules:
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  resourceNames:
  - prow-controller-manager-leader-lock
  verbs:
  - get
  - update
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - create
- apiGroups:
  - ""
  resources:
  - configmaps
  resourceNames:
  - prow-controller-manager-leader-lock
  verbs:
  - get
  - update
- apiGroups:
  - ""
  resources:
  - configmaps
  - events
  verbs:
  - create
- apiGroups:
  - prow.k8s.io
  resources:
  - prowjobs
  verbs:
  - get
  - update
  - list
  - watch
  - patch
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: test-pods
  name: "prow-controller-manager"
rules:
- apiGroups:
   - ""
  resources:
  - pods
  verbs:
  - create
  - delete
  - list
  - watch
  - get
  - patch
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "prow-controller-manager"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "prow-controller-manager"
subjects:
- kind: ServiceAccount
  name: "prow-controller-manager"
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: test-pods
  name: "prow-controller-manager"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "prow-controller-manager"
subjects:
- kind: ServiceAccount
  name: "prow-controller-manager"
  namespace: default
---
kind: ServiceAccount
apiVersion: v1
metadata:
  namespace: default
  name: "sinker"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "sinker"
rules:
  - apiGroups:
    - "prow.k8s.io"
    resources:
    - prowjobs
    verbs:
    - delete
    - list
    - watch
    - get
  - apiGroups:
    - coordination.k8s.io
    resources:
    - leases
    resourceNames:
    - prow-sinker-leaderlock
    verbs:
    - get
    - update
  - apiGroups:
    - coordination.k8s.io
    resources:
    - leases
    verbs:
    - create
  - apiGroups:
    - ""
    resources:
    - configmaps
    resourceNames:
    - prow-sinker-leaderlock
    verbs:
    - get
    - update
  - apiGroups:
    - ""
    resources:
    - configmaps
    - events
    verbs:
    - create
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: test-pods
  name: "sinker"
rules:
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - delete
      - list
      - watch
      - get
      - patch
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "sinker"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "sinker"
subjects:
- kind: ServiceAccount
  name: "sinker"
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: test-pods
  name: "sinker"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "sinker"
subjects:
- kind: ServiceAccount
  name: "sinker"
  namespace: default
---
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: default
  name: "hook"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "hook"
rules:
  - apiGroups:
      - "prow.k8s.io"
    resources:
      - prowjobs
    verbs:
      - create
      - get
      - list
      - update
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - create
      - get
      - update
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "hook"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "hook"
subjects:
- kind: ServiceAccount
  name: "hook"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  namespace: default
  name: "tide"
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "tide"
rules:
  - apiGroups:
      - "prow.k8s.io"
    resources:
      - prowjobs
    verbs:
      - create
      - get
      - list
      - watch
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: default
  name: "tide"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "tide"
subjects:
- kind: ServiceAccount
  name: "tide"
#---
#
# TODO(#54) The statusreconciler component was added after our initial Prow setup
#
#apiVersion: v1
#kind: ServiceAccount
#metadata:
#  namespace: default
#  name: "statusreconciler"
#---
#
# TODO(#54) The statusreconciler component was added after our initial Prow setup
#
#kind: Role
#apiVersion: rbac.authorization.k8s.io/v1
#metadata:
#  namespace: default
#  name: "statusreconciler"
#rules:
#  - apiGroups:
#      - "prow.k8s.io"
#    resources:
#      - prowjobs
#    verbs:
#      - create
#---
#
# TODO(#54) The statusreconciler component was added after our initial Prow setup
#
#kind: RoleBinding
#apiVersion: rbac.authorization.k8s.io/v1
#metadata:
#  namespace: default
#  name: "statusreconciler"
#roleRef:
#  apiGroup: rbac.authorization.k8s.io
#  kind: Role
#  name: "statusreconciler"
#subjects:
#- kind: ServiceAccount
#  name: "statusreconciler"
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: "crier"
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: crier
rules:
- apiGroups:
    - "prow.k8s.io"
  resources:
    - "prowjobs"
  verbs:
    - "get"
    - "watch"
    - "list"
    - "patch"
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "crier"
  namespace: "default"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: "crier"
subjects:
- kind: ServiceAccount
  name: "crier"
  namespace: "default"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crier
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: crier
  template:
    metadata:
      labels:
        app: crier
    spec:
      serviceAccountName: crier
      terminationGracePeriodSeconds: 30
      containers:
      - name: crier
        image: ghcr.io/tektoncd/plumbing/k8s-prow/crier:v20220628-aa928caf31
        args:
        - --github-workers=1
        - --config-path=/etc/config/config.yaml
        - --github-endpoint=http://ghproxy
        - --github-endpoint=https://api.github.com
        - --github-token-path=/etc/github/oauth
        - --kubernetes-blob-storage-workers=1
        ports:
        - name: metrics
          containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/config
          readOnly: true
        - name: oauth
          mountPath: /etc/github
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: config
      - name: oauth
        secret:
          secretName: oauth-token
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: crier
  namespace: default
  name: crier
spec:
  ports:
    - name: metrics
      port: 9090
      protocol: TCP
  selector:
    app: crier
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: prow-pipeline
  namespace: default
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: prow-pipeline
rules:
- apiGroups:
  - tekton.dev
  resources:
  - pipelineruns
  - pipelineresources
  verbs:
  - create
  - delete
  - get
  - list
  - update
  - watch
- apiGroups:
  - prow.k8s.io
  resources:
  - prowjobs
  - prowjobs/status
  verbs:
  - get
  - list
  - watch
  - update
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: prow-pipeline
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prow-pipeline
subjects:
- kind: ServiceAccount
  name: prow-pipeline
  namespace: default
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: prow-pipeline
  namespace: default
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: prow-pipeline
  template:
    metadata:
      labels:
        app: prow-pipeline
    spec:
      serviceAccountName: prow-pipeline
      containers:
      - name: pipeline
        image: ghcr.io/tektoncd/plumbing/k8s-prow/pipeline:v20220628-aa928caf31
        args:
        - --all-contexts
        - --config=/etc/prow-config/config.yaml
        volumeMounts:
        - mountPath: /etc/prow-config
          name: prow-config
          readOnly: true
      volumes:
      - name: prow-config
        configMap:
          name: config
---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: default
  name: needs-rebase
  labels:
    app: needs-rebase
spec:
  replicas: 1
  selector:
    matchLabels:
      app: needs-rebase
  template:
    metadata:
      labels:
        app: needs-rebase
    spec:
      terminationGracePeriodSeconds: 180
      containers:
      - name: needs-rebase
        image: ghcr.io/tektoncd/plumbing/k8s-prow/needs-rebase:v20220628-aa928caf31
        imagePullPolicy: Always
        args:
        - --dry-run=false
        - --github-endpoint=http://ghproxy
        - --github-endpoint=https://api.github.com
        - --github-token-path=/etc/github/oauth
        - --update-period=6h
        ports:
          - name: http
            containerPort: 8888
        volumeMounts:
        - name: hmac
          mountPath: /etc/webhook
          readOnly: true
        - name: oauth
          mountPath: /etc/github
          readOnly: true
        - name: plugins
          mountPath: /etc/plugins
          readOnly: true
      volumes:
      - name: hmac
        secret:
          secretName: hmac-token
      - name: oauth
        secret:
          secretName: oauth-token
      - name: plugins
        configMap:
          name: plugins
---
apiVersion: v1
kind: Service
metadata:
  namespace: default
  name: needs-rebase
spec:
  selector:
    app: needs-rebase
  ports:
  - port: 80
    targetPort: 8888
  type: NodePort
